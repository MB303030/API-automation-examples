name:gemini

on:
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Select which performance test to run'
        required: true
        default: 'all'
        type: choice
        options: [all, smoke, load, spike]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4
      
      - name: Setup k6
        uses: grafana/setup-k6-action@v1

      - name: Run Performance Suite
        run: |
          TEST_TYPE="${{ github.event.inputs.test_type }}"
          declare -A TESTS=( 
            ["smoke"]="tests/performance/smoke/dummyjson-smoke.js" 
            ["load"]="tests/performance/load/dummyjson-load.js" 
            ["spike"]="tests/performance/spike/dummyjson-spike.js" 
          )

          for TEST in smoke load spike; do
            if [[ "$TEST_TYPE" == "all" || "$TEST_TYPE" == "$TEST" ]]; then
              echo "RUN_${TEST^^}=true" >> $GITHUB_ENV
              echo "ðŸš€ Running ${TEST^} test..."
              # We use '|| true' to ensure the workflow continues to the report generation even if k6 fails
              k6 run "${TESTS[$TEST]}" --out json="k6-$TEST.json" 2>&1 | tee "k6-$TEST-output.txt" || true
            else
              echo "RUN_${TEST^^}=false" >> $GITHUB_ENV
            fi
          done

      - name: Create Unified Performance Report
        if: always()
        run: |
          echo "# ðŸš€ PERFORMANCE INTELLIGENCE COMMAND CENTER" >> $GITHUB_STEP_SUMMARY
          echo "> **Generated:** $(date) | **Test Mode:** ${{ github.event.inputs.test_type }}" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY

          render_test() {
            NAME=$1; TITLE=$2; MAX_VUS=$3; LINE=$4; FILE="k6-${NAME}-output.txt"
            if [ ! -s "$FILE" ]; then return; fi

            # 1. UNIFIED FAILURE DETECTION (The Source of Truth)
            # If k6 output contains the failure 'âœ—' or the threshold crossed message
            if grep -q "âœ—" "$FILE" || grep -q "thresholds on metrics.*crossed" "$FILE"; then 
                TEST_FAILED=true
            else 
                TEST_FAILED=false
            fi
            
            # 2. RENDER TITLE & LOAD PATTERN
            echo "## ðŸ“¶ ${TITLE} TEST ANALYSIS" >> $GITHUB_STEP_SUMMARY
            
            echo '```mermaid' >> $GITHUB_STEP_SUMMARY
            echo 'xychart-beta' >> $GITHUB_STEP_SUMMARY
            echo "    title \"${TITLE} - Virtual Users Load Pattern\"" >> $GITHUB_STEP_SUMMARY
            echo "    y-axis \"Virtual Users\" 0 --> ${MAX_VUS}" >> $GITHUB_STEP_SUMMARY
            echo "    line ${LINE}" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY

            # 3. SHOW THE ENTIRE METRIC BLOCK (Transparency)
            echo "### ðŸŽ¯ Detailed Threshold Metrics" >> $GITHUB_STEP_SUMMARY
            echo "Showing full diagnostic output from k6 core:" >> $GITHUB_STEP_SUMMARY
            echo '```diff' >> $GITHUB_STEP_SUMMARY
            # We extract the metrics block. 'diff' formatting makes it look professional.
            grep -E "âœ“|âœ—|http_req|checks" "$FILE" | grep -v "\[.*\]" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY

            # 4. ALIGNED ANALYSIS (No contradictions)
            echo "### ðŸ§  Intelligent Analysis & Advice" >> $GITHUB_STEP_SUMMARY
            if [ "$TEST_FAILED" = "true" ]; then
              echo "#### ðŸ”´ STATUS: PERFORMANCE FAILURE" >> $GITHUB_STEP_SUMMARY
              echo "- **Observation:** One or more thresholds (latency/errors) were violated during the ${NAME} phase." >> $GITHUB_STEP_SUMMARY
              echo "- **Impact:** The system cannot safely handle ${MAX_VUS} users without degrading." >> $GITHUB_STEP_SUMMARY
              echo "- **Action:** **BLOCK DEPLOYMENT.** Review the specific red 'âœ—' markers in the table above." >> $GITHUB_STEP_SUMMARY
            else
              echo "#### ðŸŸ¢ STATUS: SYSTEM HEALTHY" >> $GITHUB_STEP_SUMMARY
              echo "- **Observation:** All metrics remained within green safety margins." >> $GITHUB_STEP_SUMMARY
              echo "- **Impact:** RESILIENT. The application is stable under this specific load." >> $GITHUB_STEP_SUMMARY
              echo "- **Action:** **PROCEED.** No regressions detected." >> $GITHUB_STEP_SUMMARY
            fi
            echo "---" >> $GITHUB_STEP_SUMMARY
          }

          # Execute Renderings
          [ "$RUN_SMOKE" == "true" ] && render_test "smoke" "SMOKE" 5 "[1, 3, 5, 5, 0]"
          [ "$RUN_LOAD" == "true" ] && render_test "load" "LOAD" 120 "[10, 50, 100, 120, 120, 30]"
          [ "$RUN_SPIKE" == "true" ] && render_test "spike" "SPIKE" 400 "[0, 400, 400, 0]"

          # ðŸ† FINAL EXECUTIVE VERDICT (Scans all outputs for any failure)
          echo "# ðŸ† FINAL DEPLOYMENT VERDICT" >> $GITHUB_STEP_SUMMARY
          if grep -rq "âœ—" k6-*-output.txt || grep -rq "crossed" k6-*-output.txt; then
            echo "## âŒ VERDICT: REJECTED" >> $GITHUB_STEP_SUMMARY
            echo "> **Stakeholder Summary:** Performance goals were not met. Check the specific failures in the detailed sections above. Deployment is not recommended until the bottlenecks are resolved." >> $GITHUB_STEP_SUMMARY
          else
            echo "## âœ… VERDICT: APPROVED" >> $GITHUB_STEP_SUMMARY
            echo "> **Stakeholder Summary:** All performance suites (Smoke, Load, Spike) passed. The application meets the required service level objectives for production launch." >> $GITHUB_STEP_SUMMARY
          fi
