name: SHOW region report Performance

on:
  workflow_dispatch:
    inputs:
      execution_mode:
        description: 'Choose testing mode'
        required: true
        default: 'single-region'
        type: choice
        options:
          - single-region
          - multi-region
      test_type:
        description: 'Select which performance test to run'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - smoke
          - load
          - spike
          - stress
  schedule:
    - cron: '0 8 * * 1'  # Every Monday at 8 AM UTC
    - cron: '0 0 * * 0'  # Every Sunday at midnight UTC

permissions:
  contents: read
  actions: write
  checks: write
  pages: write
  id-token: write

concurrency:
  group: performance-${{ github.ref }}
  cancel-in-progress: true

env:
  K6_CLOUD_TOKEN: ${{ secrets.K6_CLOUD_TOKEN }}
  TEST_ENVIRONMENT: production
  REPORT_TIMESTAMP: ${{ github.run_id }}-${{ github.run_attempt }}
  NODE_VERSION: '20'

jobs:
  # ============================================================
  # SINGLE REGION PERFORMANCE TESTING
  # ============================================================
  single-region-test:
    if: github.event.inputs.execution_mode == 'single-region'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    env:
      REGION: 'us-west'
      REGION_NAME: 'US West (California)'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          
      - name: Setup k6
        uses: grafana/setup-k6-action@v1
        
      - name: Verify test files exist
        run: |
          echo "üîç Checking for test files..."
          if [ ! -d "tests/performance" ]; then
            echo "‚ùå Error: tests/performance directory not found!"
            exit 1
          fi
          
          declare -A TESTS=(
            ["smoke"]="tests/performance/smoke/dummyjson-smoke.js"
            ["load"]="tests/performance/load/dummyjson-load.js"
            ["spike"]="tests/performance/spike/dummyjson-spike.js"
            ["stress"]="tests/performance/stress/dummyjson-stress.js"
          )
          
          for TEST in smoke load spike stress; do
            if [ -f "${TESTS[$TEST]}" ]; then
              echo "‚úÖ Found $TEST test: ${TESTS[$TEST]}"
            else
              echo "‚ö†Ô∏è  Missing $TEST test: ${TESTS[$TEST]}"
            fi
          done
          
      - name: Determine which tests to run
        run: |
          TEST_TYPE="${{ github.event.inputs.test_type }}"
          echo "Test Type: $TEST_TYPE"
          
          if [ "$TEST_TYPE" = "smoke" ]; then
            echo "RUN_SMOKE=true" >> $GITHUB_ENV
            echo "RUN_LOAD=false" >> $GITHUB_ENV
            echo "RUN_SPIKE=false" >> $GITHUB_ENV
            echo "RUN_STRESS=false" >> $GITHUB_ENV
          elif [ "$TEST_TYPE" = "load" ]; then
            echo "RUN_SMOKE=false" >> $GITHUB_ENV
            echo "RUN_LOAD=true" >> $GITHUB_ENV
            echo "RUN_SPIKE=false" >> $GITHUB_ENV
            echo "RUN_STRESS=false" >> $GITHUB_ENV
          elif [ "$TEST_TYPE" = "spike" ]; then
            echo "RUN_SMOKE=false" >> $GITHUB_ENV
            echo "RUN_LOAD=false" >> $GITHUB_ENV
            echo "RUN_SPIKE=true" >> $GITHUB_ENV
            echo "RUN_STRESS=false" >> $GITHUB_ENV
          elif [ "$TEST_TYPE" = "stress" ]; then
            echo "RUN_SMOKE=false" >> $GITHUB_ENV
            echo "RUN_LOAD=false" >> $GITHUB_ENV
            echo "RUN_SPIKE=false" >> $GITHUB_ENV
            echo "RUN_STRESS=true" >> $GITHUB_ENV
          else
            echo "RUN_SMOKE=true" >> $GITHUB_ENV
            echo "RUN_LOAD=true" >> $GITHUB_ENV
            echo "RUN_SPIKE=true" >> $GITHUB_ENV
            echo "RUN_STRESS=true" >> $GITHUB_ENV
          fi
          
          echo "Tests to run:"
          echo "  Smoke: ${RUN_SMOKE}"
          echo "  Load: ${RUN_LOAD}"
          echo "  Spike: ${RUN_SPIKE}"
          echo "  Stress: ${RUN_STRESS}"
          
      - name: Run Selected Performance Tests
        run: |
          set -euo pipefail
          
          declare -A TESTS=(
            ["smoke"]="tests/performance/smoke/dummyjson-smoke.js"
            ["load"]="tests/performance/load/dummyjson-load.js"
            ["spike"]="tests/performance/spike/dummyjson-spike.js"
            ["stress"]="tests/performance/stress/dummyjson-stress.js"
          )
          
          FAILED_TESTS=()
          
          for TEST in smoke load spike stress; do
            RUN_VAR="RUN_${TEST^^}"
            if [ "${!RUN_VAR}" = "true" ]; then
              echo "================================================================="
              echo "üöÄ Running ${TEST^} Test"
              echo "================================================================="
              echo "Test file: ${TESTS[$TEST]}"
              
              if [ ! -f "${TESTS[$TEST]}" ]; then
                echo "‚ùå Error: File ${TESTS[$TEST]} not found!"
                echo "Skipping $TEST test..."
                FAILED_TESTS+=("$TEST:FILE_NOT_FOUND")
                continue
              fi
              
              # Create timestamp for this test
              TIMESTAMP=$(date +%Y%m%d-%H%M%S)
              
              # Run k6 test
              echo "Starting test at: $(date)"
              if k6 run "${TESTS[$TEST]}" \
                --out json="k6-${TEST}-results-${TIMESTAMP}.json" \
                --tag test_type="$TEST" \
                --tag region="$REGION" \
                --tag environment="$TEST_ENVIRONMENT" \
                2>&1 | tee "k6-${TEST}-output-${TIMESTAMP}.txt"; then
                
                echo "‚úÖ ${TEST^} test completed successfully"
                echo "Results saved to: k6-${TEST}-results-${TIMESTAMP}.json"
              else
                echo "‚ùå ${TEST^} test failed"
                FAILED_TESTS+=("$TEST:EXECUTION_FAILED")
              fi
              
              echo "Test completed at: $(date)"
              echo ""
            fi
          done
          
          # Report test failures
          if [ ${#FAILED_TESTS[@]} -gt 0 ]; then
            echo "========================================"
            echo "‚ö†Ô∏è  Some tests failed:"
            for failure in "${FAILED_TESTS[@]}"; do
              echo "  - $failure"
            done
            echo "========================================"
          else
            echo "========================================"
            echo "üéâ All tests completed successfully!"
            echo "========================================"
          fi
          
      - name: Create Single Region Performance Report
        if: always()
        run: |
          set -euo pipefail
          
          echo "# üìä SINGLE REGION PERFORMANCE REPORT" > single-region-report.md
          echo "" >> single-region-report.md
          echo "**üìÖ Report Time:** $(date '+%Y-%m-%d %H:%M:%S UTC')" >> single-region-report.md
          echo "**üéØ Test Type:** ${{ github.event.inputs.test_type }}" >> single-region-report.md
          echo "**üåç Region:** ${{ env.REGION_NAME }}" >> single-region-report.md
          echo "**üè∑Ô∏è Run ID:** ${{ env.REPORT_TIMESTAMP }}" >> single-region-report.md
          echo "" >> single-region-report.md
          
          # Find all test output files
          OUTPUT_FILES=$(ls k6-*-output-*.txt 2>/dev/null || true)
          
          if [ -z "$OUTPUT_FILES" ]; then
            echo "## ‚ùå No Test Results Found" >> single-region-report.md
            echo "" >> single-region-report.md
            echo "No test output files were generated. Please check if tests ran correctly." >> single-region-report.md
          else
            echo "## üìã Test Execution Summary" >> single-region-report.md
            echo "" >> single-region-report.md
            echo "| Test | Status | Execution Time | Results File |" >> single-region-report.md
            echo "|------|--------|----------------|--------------|" >> single-region-report.md
            
            for OUTPUT_FILE in $OUTPUT_FILES; do
              TEST_NAME=$(echo "$OUTPUT_FILE" | cut -d'-' -f2)
              TIMESTAMP=$(echo "$OUTPUT_FILE" | cut -d'-' -f4 | cut -d'.' -f1)
              
              # Check if test passed
              if grep -q "‚úì" "$OUTPUT_FILE"; then
                STATUS="‚úÖ PASS"
              elif grep -q "‚ùå" "$OUTPUT_FILE"; then
                STATUS="üî¥ FAIL"
              else
                STATUS="‚ö†Ô∏è UNKNOWN"
              fi
              
              # Get execution time
              START_TIME=$(grep "Starting test at:" "$OUTPUT_FILE" | cut -d':' -f2-)
              END_TIME=$(grep "Test completed at:" "$OUTPUT_FILE" | tail -1 | cut -d':' -f2-)
              
              echo "| $TEST_NAME | $STATUS | $START_TIME to $END_TIME | [$OUTPUT_FILE](./$OUTPUT_FILE) |" >> single-region-report.md
            done
            echo "" >> single-region-report.md
          fi
          
          # Add to GitHub summary
          cat single-region-report.md >> $GITHUB_STEP_SUMMARY
          
      - name: Upload Single Region Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: single-region-results-${{ env.REPORT_TIMESTAMP }}
          path: |
            k6-*.json
            k6-*.txt
            single-region-report.md
          retention-days: 90
          compression-level: 9

  # ============================================================
  # MULTI-REGION PERFORMANCE TESTING
  # ============================================================
  multi-region-tests:
    if: github.event.inputs.execution_mode == 'multi-region'
    defaults:
      run:
        shell: bash
        
    strategy:
      matrix:
        region_config:
          - runner: ubuntu-latest
            region_label: "US West (California)"
            region_id: us-west
            region_emoji: "üá∫üá∏"
          - runner: windows-latest
            region_label: "EU West (Netherlands)"
            region_id: eu-west
            region_emoji: "üá≥üá±"
          - runner: macos-latest
            region_label: "Asia Pacific (Singapore)"
            region_id: apac-sg
            region_emoji: "üá∏üá¨"
      fail-fast: false
      max-parallel: 3
    
    runs-on: ${{ matrix.region_config.runner }}
    timeout-minutes: 45
    
    env:
      REGION_ID: ${{ matrix.region_config.region_id }}
      REGION_LABEL: ${{ matrix.region_config.region_label }}
      REGION_EMOJI: ${{ matrix.region_config.region_emoji }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup k6
        uses: grafana/setup-k6-action@v1
        
      - name: Determine test to run
        run: |
          TEST_TYPE="${{ github.event.inputs.test_type }}"
          
          if [ "$TEST_TYPE" = "all" ]; then
            echo "SPECIFIC_TEST=load" >> $GITHUB_ENV
            echo "NOTE=Using load test for multi-region comparison" >> $GITHUB_ENV
          else
            echo "SPECIFIC_TEST=$TEST_TYPE" >> $GITHUB_ENV
            echo "NOTE=Running $TEST_TYPE test in all regions" >> $GITHUB_ENV
          fi
          
          echo "üåç Region: $REGION_LABEL"
          echo "üß™ Test: $SPECIFIC_TEST"
          
      - name: Run ${{ env.SPECIFIC_TEST }} test in ${{ env.REGION_LABEL }}
        id: run-test
        run: |
          set -euo pipefail
          
          TEST_FILE="tests/performance/$SPECIFIC_TEST/dummyjson-$SPECIFIC_TEST.js"
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          
          echo "üìÅ Test File: $TEST_FILE"
          echo "üïê Start Time: $(date)"
          
          if [ ! -f "$TEST_FILE" ]; then
            echo "‚ùå Error: Test file not found!"
            echo "Available tests in tests/performance/:"
            find tests/performance -name "*.js" -type f || true
            exit 1
          fi
          
          # Run the test
          k6 run "$TEST_FILE" \
            --tag region="$REGION_ID" \
            --tag region_name="$REGION_LABEL" \
            --tag test_type="$SPECIFIC_TEST" \
            --tag runner="${{ matrix.region_config.runner }}" \
            --tag environment="$TEST_ENVIRONMENT" \
            --out json="results-$REGION_ID-$TIMESTAMP.json" \
            --summary-export="summary-$REGION_ID-$TIMESTAMP.json" \
            2>&1 | tee "output-$REGION_ID-$TIMESTAMP.txt"
          
          echo "‚úÖ Test completed successfully"
          echo "üïê End Time: $(date)"
          
      - name: Extract and Store Metrics
        if: always()
        run: |
          OUTPUT_FILE="output-$REGION_ID-*.txt"
          LATEST_OUTPUT=$(ls -t $OUTPUT_FILE 2>/dev/null | head -1 || true)
          
          if [ -f "$LATEST_OUTPUT" ]; then
            # Extract metrics
            AVG_RESPONSE=$(grep -oP 'http_req_duration.*avg=\K[0-9.]+' "$LATEST_OUTPUT" 2>/dev/null || echo "0")
            P95_RESPONSE=$(grep -oP 'http_req_duration.*p\(95\)=\K[0-9.]+' "$LATEST_OUTPUT" 2>/dev/null || echo "0")
            ERROR_RATE=$(grep -oP 'http_req_failed.*rate=\K[0-9.]+' "$LATEST_OUTPUT" 2>/dev/null || echo "0")
            VUS_MAX=$(grep -oP 'vus_max.*max=\K[0-9.]+' "$LATEST_OUTPUT" 2>/dev/null || echo "0")
            
            # Convert to percentages
            ERROR_PCT=$(echo "scale=2; $ERROR_RATE * 100" | bc 2>/dev/null || echo "0.00")
            
            # Save metrics
            echo "AVG_RESPONSE=$AVG_RESPONSE" >> $GITHUB_ENV
            echo "P95_RESPONSE=$P95_RESPONSE" >> $GITHUB_ENV
            echo "ERROR_PCT=$ERROR_PCT" >> $GITHUB_ENV
            echo "VUS_MAX=$VUS_MAX" >> $GITHUB_ENV
            
            echo "üìä Metrics extracted for $REGION_LABEL:"
            echo "  Avg Response: ${AVG_RESPONSE}ms"
            echo "  P95 Response: ${P95_RESPONSE}ms"
            echo "  Error Rate: ${ERROR_PCT}%"
            echo "  Max VUs: ${VUS_MAX}"
          else
            echo "‚ö†Ô∏è  No output file found for metrics extraction"
          fi
          
      - name: Create Region Summary
        if: always()
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          
          cat > "region-summary-$REGION_ID-$TIMESTAMP.md" << EOF
          # $REGION_EMOJI $REGION_LABEL - Performance Results
          
          **Test Type:** $SPECIFIC_TEST
          **Region:** $REGION_LABEL ($REGION_ID)
          **Runner:** ${{ matrix.region_config.runner }}
          **Timestamp:** $TIMESTAMP
          
          ## üìä Performance Metrics
          
          | Metric | Value | Status |
          |--------|-------|--------|
          | Average Response | ${AVG_RESPONSE:-N/A}ms | $(if [ "${AVG_RESPONSE:-0}" != "N/A" ] && (( $(echo "${AVG_RESPONSE:-0} < 1000" | bc -l 2>/dev/null || echo 1) )); then echo "‚úÖ Good"; elif (( $(echo "${AVG_RESPONSE:-0} < 2000" | bc -l 2>/dev/null || echo 1) )); then echo "‚ö†Ô∏è Acceptable"; else echo "üî¥ Poor"; fi) |
          | P95 Response | ${P95_RESPONSE:-N/A}ms | $(if [ "${P95_RESPONSE:-0}" != "N/A" ] && (( $(echo "${P95_RESPONSE:-0} < 2000" | bc -l 2>/dev/null || echo 1) )); then echo "‚úÖ Good"; elif (( $(echo "${P95_RESPONSE:-0} < 4000" | bc -l 2>/dev/null || echo 1) )); then echo "‚ö†Ô∏è Acceptable"; else echo "üî¥ Poor"; fi) |
          | Error Rate | ${ERROR_PCT:-N/A}% | $(if [ "${ERROR_PCT:-0}" != "N/A" ] && (( $(echo "${ERROR_PCT:-0} < 1" | bc -l 2>/dev/null || echo 1) )); then echo "‚úÖ Excellent"; elif (( $(echo "${ERROR_PCT:-0} < 5" | bc -l 2>/dev/null || echo 1) )); then echo "‚ö†Ô∏è Acceptable"; else echo "üî¥ Critical"; fi) |
          | Max Virtual Users | ${VUS_MAX:-N/A} | $(if [ "${VUS_MAX:-0}" != "N/A" ] && (( $(echo "${VUS_MAX:-0} > 0" | bc -l 2>/dev/null || echo 0) )); then echo "‚úÖ Load Applied"; else echo "‚ö†Ô∏è No Load"; fi) |
          
          ## üìà Test Details
          
          **Test File:** \`tests/performance/$SPECIFIC_TEST/dummyjson-$SPECIFIC_TEST.js\`
          
          **Runner Information:**
          - OS: ${{ runner.os }}
          - Arch: ${{ runner.arch }}
          - Runner Name: ${{ runner.name }}
          
          ## üéØ Threshold Results
          
          \`\`\`
          $(if [ -f "output-$REGION_ID-$TIMESTAMP.txt" ]; then grep -A1 "‚úì\|‚úó" "output-$REGION_ID-$TIMESTAMP.txt" | head -20 || echo "No threshold data available"; fi)
          \`\`\`
          
          EOF
          
      - name: Upload Regional Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: region-$REGION_ID-results-${{ env.REPORT_TIMESTAMP }}
          path: |
            results-$REGION_ID-*.json
            summary-$REGION_ID-*.json
            output-$REGION_ID-*.txt
            region-summary-$REGION_ID-*.md
          retention-days: 90

  # ============================================================
  # REGIONAL ANALYSIS & COMBINED REPORT
  # ============================================================
  regional-analysis:
    if: github.event.inputs.execution_mode == 'multi-region'
    runs-on: ubuntu-latest
    needs: multi-region-tests
    timeout-minutes: 15
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Download all regional results
        uses: actions/download-artifact@v4
        with:
          path: regional-results
          pattern: region-*-results-*
          merge-multiple: true
          
      - name: Install analysis tools
        run: |
          sudo apt-get update
          sudo apt-get install -y jq bc
          
      - name: Generate Global Analysis Report
        run: |
          set -euo pipefail
          
          echo "# üåç GLOBAL PERFORMANCE ANALYSIS REPORT" > global-report.md
          echo "" >> global-report.md
          
          # Gather region data
          REGIONS=()
          REGION_DATA=()
          
          for REGION_ID in us-west eu-west apac-sg; do
            SUMMARY_FILE=$(find regional-results -name "summary-$REGION_ID-*.json" | head -1)
            
            if [ -f "$SUMMARY_FILE" ]; then
              AVG=$(jq -r '.metrics.http_req_duration.values.avg // 0' "$SUMMARY_FILE" 2>/dev/null || echo "0")
              P95=$(jq -r '.metrics.http_req_duration.values."p(95)" // 0' "$SUMMARY_FILE" 2>/dev/null || echo "0")
              ERR=$(jq -r '.metrics.http_req_failed.values.rate // 0' "$SUMMARY_FILE" 2>/dev/null || echo "0")
              ERR_PCT=$(echo "scale=2; $ERR * 100" | bc 2>/dev/null || echo "0.00")
              
              REGIONS+=("$REGION_ID")
              REGION_DATA+=("$AVG:$P95:$ERR_PCT")
              
              echo "‚úÖ Found data for $REGION_ID: avg=${AVG}ms, p95=${P95}ms, err=${ERR_PCT}%"
            else
              echo "‚ö†Ô∏è  No data found for $REGION_ID"
            fi
          done
          
          # Generate report
          echo "**Report Generated:** $(date '+%Y-%m-%d %H:%M:%S UTC')" >> global-report.md
          echo "**Test Type:** ${{ github.event.inputs.test_type }}" >> global-report.md
          echo "**Regions Tested:** ${#REGIONS[@]}" >> global-report.md
          echo "" >> global-report.md
          
          echo "## üìä Regional Performance Comparison" >> global-report.md
          echo "" >> global-report.md
          echo "| Region | Avg Response | P95 Response | Error Rate | Status |" >> global-report.md
          echo "|--------|--------------|--------------|------------|--------|" >> global-report.md
          
          for i in "${!REGIONS[@]}"; do
            IFS=':' read -r AVG P95 ERR_PCT <<< "${REGION_DATA[$i]}"
            
            case "${REGIONS[$i]}" in
              us-west) LABEL="üá∫üá∏ US West" ;;
              eu-west) LABEL="üá≥üá± EU West" ;;
              apac-sg) LABEL="üá∏üá¨ APAC Singapore" ;;
              *) LABEL="${REGIONS[$i]}" ;;
            esac
            
            # Determine status
            STATUS="‚úÖ Good"
            if (( $(echo "$ERR_PCT > 10" | bc -l 2>/dev/null || echo 0) )); then
              STATUS="üî¥ Critical"
            elif (( $(echo "$ERR_PCT > 5" | bc -l 2>/dev/null || echo 0) )); then
              STATUS="üü° Warning"
            elif (( $(echo "$AVG > 3000" | bc -l 2>/dev/null || echo 0) )); then
              STATUS="üü° Slow"
            fi
            
            echo "| $LABEL | ${AVG}ms | ${P95}ms | ${ERR_PCT}% | $STATUS |" >> global-report.md
          done
          echo "" >> global-report.md
          
          # Add to GitHub summary
          cat global-report.md >> $GITHUB_STEP_SUMMARY
          
      - name: Upload Global Report
        uses: actions/upload-artifact@v4
        with:
          name: global-analysis-report-${{ env.REPORT_TIMESTAMP }}
          path: |
            global-report.md
            regional-results/
          retention-days: 90

  # ============================================================
  # FINAL SUMMARY & CLEANUP
  # ============================================================
  final-summary:
    runs-on: ubuntu-latest
    needs: 
      - single-region-test
      - regional-analysis
    if: always()
    timeout-minutes: 5
    
    steps:
      - name: Generate Workflow Summary
        run: |
          echo "# üèÅ PERFORMANCE TESTING WORKFLOW COMPLETE" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## üìä Workflow Information" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **Workflow** | ${{ github.workflow }}" >> $GITHUB_STEP_SUMMARY
          echo "| **Run ID** | ${{ github.run_id }} (Attempt ${{ github.run_attempt }})" >> $GITHUB_STEP_SUMMARY
          echo "| **Mode** | ${{ github.event.inputs.execution_mode }}" >> $GITHUB_STEP_SUMMARY
          echo "| **Test Type** | ${{ github.event.inputs.test_type }}" >> $GITHUB_STEP_SUMMARY
          echo "| **Trigger** | ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "| **Branch** | ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "| **Commit** | ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## üì¶ Generated Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ github.event.inputs.execution_mode }}" = "single-region" ]; then
            echo "- **Single Region Results:** Detailed test results from US West region" >> $GITHUB_STEP_SUMMARY
            echo "- **Performance Report:** Comprehensive analysis with metrics and graphs" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **Regional Results:** Individual test results from 3 global regions" >> $GITHUB_STEP_SUMMARY
            echo "- **Global Analysis Report:** Comparative analysis across regions" >> $GITHUB_STEP_SUMMARY
            echo "- **Regional Summaries:** Individual summaries for US, EU, and APAC" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## üîß Next Steps" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ job.status }}" = "success" ]; then
            echo "‚úÖ **All tests completed successfully!**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "1. **Review the artifacts** for detailed metrics and analysis" >> $GITHUB_STEP_SUMMARY
            echo "2. **Check the generated reports** for performance insights" >> $GITHUB_STEP_SUMMARY
            echo "3. **Share findings** with your team" >> $GITHUB_STEP_SUMMARY
            echo "4. **Schedule follow-up tests** if needed" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è **Some tests may have failed or been skipped**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "1. **Check the workflow logs** for error details" >> $GITHUB_STEP_SUMMARY
            echo "2. **Review uploaded artifacts** for partial results" >> $GITHUB_STEP_SUMMARY
            echo "3. **Verify test file paths** and configurations" >> $GITHUB_STEP_SUMMARY
            echo "4. **Retry the workflow** after fixing any issues" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "*Workflow completed at: $(date '+%Y-%m-%d %H:%M:%S UTC')*" >> $GITHUB_STEP_SUMMARY
